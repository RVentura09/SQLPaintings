{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation and export "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data import and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read your CSV file into a Pandas dataframe\n",
    "df_artist= pd.read_csv(\"artist.csv\")\n",
    "df_artist.head()#Initial check to verify the columns and data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This df has \" + str(df_artist.shape[0])+\" rows and \"+str(df_artist.shape[1])+\" colums.\" )\n",
    "print(\"v---------Null Values---------v\")\n",
    "print(df_artist.isnull().sum())#Check any null values , in this case null values are only on middle names which is a column we can drop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artist.drop(\"middle_names\", axis=1, inplace=True)#Drop the unnecessary column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artist.dtypes # Verify the data type of each column.Eventhough birth and death columns refer to dates only have the year therefore \n",
    "#we keep the int dtype for now "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 canvas_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read your CSV file into a Pandas dataframe\n",
    "df_canvas_size= pd.read_csv(\"canvas_size.csv\")\n",
    "df_canvas_size.head()#Initial check to verify the columns and data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This df has \" + str(df_canvas_size.shape[0])+\" rows and \"+str(df_canvas_size.shape[1])+\" colums.\" )\n",
    "print(\"v---------Null Values---------v\")\n",
    "print(df_canvas_size.isnull().sum())#Check any null values , all paintings should have a height value we will drop the null values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_canvas_size.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_canvas_size.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 image_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read your CSV file into a Pandas dataframe\n",
    "df_image_link= pd.read_csv(\"image_link.csv\")\n",
    "df_image_link.head()#Initial check to verify the columns and data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This df has \" + str(df_image_link.shape[0])+\" rows and \"+str(df_image_link.shape[1])+\" colums.\" )\n",
    "print(\"v---------Null Values---------v\")\n",
    "print(df_image_link.isnull().sum())#Check any null values ,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_link.dropna(inplace=True)\n",
    "df_image_link.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 museum_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read your CSV file into a Pandas dataframe\n",
    "df_museum_hours= pd.read_csv(\"museum_hours.csv\")\n",
    "df_museum_hours.head()#Initial check to verify the columns and data \n",
    "#openning and closing hours include the \"AM\" and \"PM\" in their values , we will remove those and convert it to 24HR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the last 3 characters to a new column\n",
    "df_museum_hours['openTime'] = df_museum_hours['open'].str[-2:]\n",
    "df_museum_hours['open'] = df_museum_hours['open'].str[:-3]\n",
    "############################################################\n",
    "df_museum_hours['CloseTime'] = df_museum_hours['close'].str[-2:]\n",
    "df_museum_hours['close'] = df_museum_hours['close'].str[:-3]\n",
    "df_museum_hours.head()\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert to 24-hour time\n",
    "def convert_to_24_hour(time, period):\n",
    "    if period == 'PM' and time[:2] != '12':\n",
    "        hour, minute = map(int, time.split(':'))\n",
    "        hour += 12  # Add 12 to convert to 24-hour format\n",
    "    elif period == 'AM' and time[:2] == '12':\n",
    "        hour, minute = 0, int(time.split(':')[1])  # Handle midnight (12:00 AM)\n",
    "    else:\n",
    "        hour, minute = map(int, time.split(':'))  # No conversion needed for other cases\n",
    "\n",
    "    return f'{hour:02}:{minute:02}'  # Ensure 2-digit formatting\n",
    "\n",
    "# Apply the conversion function to 'open' and 'close' columns\n",
    "df_museum_hours['open_24hr'] = df_museum_hours.apply(\n",
    "    lambda x: convert_to_24_hour(x['open'], x['openTime']), axis=1\n",
    ")\n",
    "df_museum_hours['close_24hr'] = df_museum_hours.apply(\n",
    "    lambda x: convert_to_24_hour(x['close'], x['CloseTime']), axis=1\n",
    ")\n",
    "\n",
    "# Display the modified DataFrame\n",
    "df_museum_hours.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_museum_hours.drop(['open', 'close', 'openTime', 'CloseTime'], axis=1, inplace=True)#Drop the unnecessary columns\n",
    "df_museum_hours.rename(columns={'open_24hr': 'open','close_24hr':'close'}, inplace=True)#Rename columns to original name\n",
    "df_museum_hours.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"This df has \" + str(df_museum_hours.shape[0])+\" rows and \"+str(df_museum_hours.shape[1])+\" colums.\" )\n",
    "print(\"v---------Null Values---------v\")\n",
    "print(df_museum_hours.isnull().sum())#Check any null values , in this case null values are only on middle names which is a column we can drop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_museum_hours.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 museum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read your CSV file into a Pandas dataframe\n",
    "df_museum= pd.read_csv(\"museum.csv\")\n",
    "df_museum.head()#Initial check to verify the columns and data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"This df has \" + str(df_museum.shape[0])+\" rows and \"+str(df_museum.shape[1])+\" colums.\" )\n",
    "print(\"v---------Null Values---------v\")\n",
    "print(df_museum.isnull().sum())#Check any null values , in this case null values are only on middle names which is a column we can drop\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_museum.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 product_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read your CSV file into a Pandas dataframe\n",
    "df_product_size= pd.read_csv(\"product_size.csv\")\n",
    "df_product_size.head()#Initial check to verify the columns and data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This df has \" + str(df_product_size.shape[0])+\" rows and \"+str(df_product_size.shape[1])+\" colums.\" )\n",
    "print(\"v---------Null Values---------v\")\n",
    "print(df_product_size.isnull().sum())#Check any null values , in this case null values are only on middle names which is a column we can drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product_size.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7 subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read your CSV file into a Pandas dataframe\n",
    "df_subject= pd.read_csv(\"subject.csv\")\n",
    "df_subject.head()#Initial check to verify the columns and data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This df has \" + str(df_subject.shape[0])+\" rows and \"+str(df_subject.shape[1])+\" colums.\" )\n",
    "print(\"v---------Null Values---------v\")\n",
    "print(df_subject.isnull().sum())#Check any null values , in this case null values are only on middle names which is a column we can drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subject.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.8 work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read your CSV file into a Pandas dataframe\n",
    "df_work= pd.read_csv(\"work.csv\")\n",
    "df_work.head()#Initial check to verify the columns and data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"This df has \" + str(df_work.shape[0])+\" rows and \"+str(df_work.shape[1])+\" colums.\" )\n",
    "print(\"v---------Null Values---------v\")\n",
    "print(df_work.isnull().sum())#Check any null values , in this case null values are only on middle names which is a column we can drop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_work.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. MySql Connection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input the host name ,user and password of the server\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  password=\"Vivoenalemania2024\"\n",
    ")\n",
    "\n",
    "print(mydb) #Verify the connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor=mydb.cursor()\n",
    "mycursor.execute(\"CREATE DATABASE IF NOT EXISTS sql_paintings\") # Create a Database  if not exists already \n",
    "print(\"Database created or already exists.\") # Confirmation message "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor.execute(\"SHOW DATABASES\") # Verify the existing databases, our previously created DB should be listed here\n",
    "for db in mycursor:\n",
    "    print(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the dataframe in MySQL\n",
    "engine = sqlalchemy.create_engine('mysql+mysqlconnector://root:Vivoenalemania2024@localhost/sql_painting')\n",
    "with engine.begin() as connection:\n",
    "    df.to_sql('your_table', con=connection, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['artist', 'canvas_size', 'image_link', 'museum_hours', 'museum', 'product_size', 'subject', 'work']\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(f'/Users/thoufiq/THOUFIQ/techTFQ/YouTube/VIDEOS/SQL Queries/SQL Case Studies - Datasets/Famous Paintings/Dataset/{file}.csv')\n",
    "    df.to_sql(file, con=conn, if_exists='replace', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
